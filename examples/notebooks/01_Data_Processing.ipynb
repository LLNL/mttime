{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "In this notebook we will do:\n",
    " * Instrument response correction\n",
    " * Rotate data to the \"great circle path\"\n",
    " * Save the processed waveforms as SAC files (or another format of your choice)\n",
    " \n",
    "**Notes:**\n",
    " Here I show you how to process the data using ObsPy, the goal here is to illustrate the general processing steps for waveform inversion. You can use whatever software of your choice to process your data (e.g. SAC, Matlab, etc.). I always recommend to save a copy of the raw uncorrected data and a copy of the instrument corrected data. This is important for reproducibility and quality control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import third-party libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from obspy import read, read_inventory, UTCDateTime\n",
    "from obspy.geodetics.base import gps2dist_azimuth\n",
    "from obspy.core.util.attribdict import AttribDict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"datetime.csv\"\n",
    "df = pd.read_csv(infile,parse_dates=True)\n",
    "pre_filt = (0.004,0.007,10,20) # Data processing parameters\n",
    "outfile_name = \"station.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin data processing.\n",
    "\n",
    "In this tutorial we will process data from one earthquake, but you can easily process mulitple events by reading an input file that contains multiple event origins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will go through the events in the Pandas table,\n",
    "# if your table contains multiple events it will process all of them.\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    event_dir = row.evid\n",
    "    outdir = \"%s/sac\"%event_dir # Output directory\n",
    "    \n",
    "    Path(outdir).mkdir(parents=True,exist_ok=True)\n",
    "    df[index:index+1].to_csv(\"%s/%s\"%(event_dir,\"datetime.csv\"),index=False) # save origin info to event directory\n",
    "\n",
    "    # Read response files\n",
    "    inv = read_inventory(\"%s/stations/*\"%event_dir,format='STATIONXML')\n",
    "\n",
    "    # Read data\n",
    "    st = read(\"%s/waveforms/*\"%event_dir,format='MSEED')\n",
    "\n",
    "    # Detrend and remove instrument response\n",
    "    st.detrend(type=\"linear\") # equivalent to rtr in SAC\n",
    "    st.remove_response(inventory=inv, pre_filt=pre_filt, output=\"DISP\", zero_mean=True) # correct to displacement\n",
    "    st.detrend(type=\"linear\")\n",
    "    st.detrend(type=\"demean\") # remove mean\n",
    "\n",
    "    # Define SAC headers and calculate back-azimtuh for rotation\n",
    "    origin_time = UTCDateTime(row.origin)\n",
    "    depth = row.depth*1000\n",
    "    for tr in st:\n",
    "        meta = inv.get_channel_metadata(tr.id)\n",
    "        dist, az, baz = gps2dist_azimuth(row.lat,row.lon,meta['latitude'],meta['longitude'])\n",
    "        omarker = origin_time - tr.stats.starttime\n",
    "\n",
    "        # Obspy trace headers\n",
    "        #tr.stats.coordinates = {'latitude':meta['latitude'], 'longitude':meta['longitude']}\n",
    "        tr.stats.distance = dist\n",
    "        tr.stats.back_azimuth = baz\n",
    "        # SAC headers\n",
    "        sacd = AttribDict()\n",
    "        sacd.stla = meta['latitude']\n",
    "        sacd.stlo = meta['longitude']\n",
    "        sacd.stel = meta['elevation']\n",
    "        sacd.evla = row.lat\n",
    "        sacd.evlo = row.lon\n",
    "        sacd.evdp = depth # in meters\n",
    "        sacd.az = az\n",
    "        sacd.baz = baz\n",
    "        sacd.dist = dist/1000 # convert to kilometers\n",
    "        sacd.o = 0\n",
    "        sacd.b = -1*omarker\n",
    "        tr.stats.sac = sacd\n",
    "\n",
    "    # Rotate to ZNE\n",
    "    st._rotate_to_zne(inv,components=(\"ZNE\",\"Z12\"))\n",
    "\n",
    "    # Get station names\n",
    "    netstaloccha = sorted(set(\n",
    "            [(tr.stats.network, tr.stats.station, tr.stats.location, tr.stats.channel[:-1]) for tr in st]\n",
    "            ))\n",
    "    \n",
    "    # Keep only three-component seismograms, then rotate horizontals to RT\n",
    "    for net, sta, loc, cha in netstaloccha:\n",
    "        traces = st.select(network=net,station=sta,location=loc,channel=\"%s[ZNE]\"%cha)\n",
    "        if len(traces) != 3:\n",
    "            for tr in traces:\n",
    "                st.remove(tr)\n",
    "        else:\n",
    "            traces.rotate(method=\"NE->RT\")\n",
    "    \n",
    "    # Update station names\n",
    "    netstaloccha = set(\n",
    "        [(tr.stats.network, tr.stats.station, tr.stats.location, tr.stats.channel[:-1], \"ZRT\",\n",
    "          tr.stats.sac.dist, tr.stats.sac.az, tr.stats.sac.stlo, tr.stats.sac.stla) for tr in st.select(component=\"Z\")]\n",
    "        )\n",
    "    \n",
    "    # Save station information to a Pandas table\n",
    "    header = (\"network\",\"station\",\"location\",\"channel\",\"component\",\"distance\",\"azimuth\",\"longitude\",\"latitude\")\n",
    "    df2 = pd.DataFrame(netstaloccha, columns=header)\n",
    "    df2 = df2.sort_values(\"distance\")\n",
    "    df2.to_csv(\"%s/%s\"%(event_dir,outfile_name),index=False)\n",
    "    \n",
    "    # Here I choose to save the data in SAC format\n",
    "    print(\"Saving instrument corrected data to %s.\"%outdir)\n",
    "    for tr in st:\n",
    "        tr.write(\"%s/%s\"%(outdir,tr.id),format=\"SAC\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Seismograms\n",
    "Let's take a look at the waveforms to determine the period band for moment tensor inversion. Regional earthquakes tend to have good signals in the intermediate period band (10-50 seconds). We can model this period range with a one-dimensional plane-layered Earth model.\n",
    "\n",
    "We will apply the filter on a copy of the original seismograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqmin = 0.02\n",
    "freqmax = 0.05\n",
    "corners = 2\n",
    "st_filt = st.copy()\n",
    "\n",
    "# Apply filter and taper the edges\n",
    "st_filt.filter(\"bandpass\",freqmin=freqmin,freqmax=freqmax,corners=corners,zerophase=True)\n",
    "st_filt.taper(max_percentage=0.05)\n",
    "\n",
    "# Each seismogram is normalized against each trace\n",
    "xmin = 0\n",
    "xmax = 150\n",
    "ymin = 75\n",
    "ymax = 145\n",
    "scale = 2 # scale the traces\n",
    "fig, axes = plt.subplots(1,3,figsize=(15,10))\n",
    "for component, ax in zip((\"T\",\"R\",\"Z\"),axes):\n",
    "    for tr in st_filt.select(component=component):\n",
    "        times = tr.times() - (origin_time - tr.stats.starttime)\n",
    "        tr.data /= max(abs(tr.data))\n",
    "        tr.data *= scale\n",
    "        ax.plot(times,tr.data+tr.stats.sac.dist,color=\"black\",linewidth=0.8)\n",
    "        ax.text(xmax,tr.stats.sac.dist,\"%s.%s\"%(tr.stats.network,tr.stats.station),va=\"bottom\",ha=\"right\")\n",
    "    ax.set_xlim(xmin,xmax)\n",
    "    ax.set_ylim(ymin,ymax)\n",
    "    ax.set_xlabel(\"Times [s]\")\n",
    "    ax.set_ylabel(\"Distance [km]\")\n",
    "    ax.set_title(\"%s: bp %.0f-%.0f seconds\"%(component,1/freqmax,1/freqmin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will move on to the next book on data and synthetics.**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.5.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
